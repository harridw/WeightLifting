predict(modFit, newdata=newdataB, type = "prob")
predict(modFit, newdata=newdataC, type = "prob")
predict(modFit, newdata=newdataD, type = "prob")
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
modFit <- rpart(Area ~ ., data = olive)
modFit
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata, type = "prob")
predict(modFit, newdata = newdata)
train.part <- train(Area ~ ., method = “rpart”, data = olive)
train.part <- train(Area ~ ., method = "rpart", data = olive)
train.part
train.part$finalModel
predict(train.part, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(trainSA)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", data = trainSA)
set.seed(13234)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrainSA <- predict(modFit)
predictTestSA <- predict(modFit, data = testSA)
missClass(trainSA$chd, predictTrainSA)
missClass(testSA$chd, predictTestSA)
predictTestSA <- predict(modFit, newdata = testSA)
missClass(testSA$chd, predictTestSA)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", familiy = "binomial", data = trainSA)
predictTrainSA <- predict(modFit)
predictTestSA <- predict(modFit, newdata = testSA)
missClass(trainSA$chd, predictTrainSA)
predictTestSA <- predict(modFit, newdata = testSA)
missClass(testSA$chd, predictTestSA)
predictTestSA <- predict(modFit, newdata = testSA)
missClass(testSA$chd, predictTestSA)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values
)/length(values)}
set.seed(13234)
•	modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA , method = "glm", family = “binomial”)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA , method = "glm", family = “binomial”)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
library(caret)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
predictTrainSA <- missClass(trainSA$chd, predictTrainSA)
predictTrainSA <- predict(modFit)
predictTestSA <- predict(modFit, newdata = testSA)
missClass(trainSA$chd, predictTrainSA)
missClass(testSA$chd, predictTestSA)
library(caret); library(ElemStatLearn);
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
trainRF <- train(y ~ ., data = vowel.train, method = "rf")
predictTest <- predict(trainRF, newdata = vowel.test)
set.seed(33833)
trainRF <- train(y ~ ., data = vowel.train, method = "rf")
varImp(modFit)
varImp(trainRF)
trainRF <- train(y ~ ., data = vowel.train, method = "rf")
predictTest <- predict(trainRF, newdata = vowel.test)
varImp(trainRF)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
trainRF <- train(y ~ ., data = vowel.train, method = "rf")
predictTest <- predict(trainRF, newdata = vowel.test)
varImp(trainRF)
library(caret); library(ElemStatLearn);
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modRF <- train(y ~ ., data = vowel.train, method = "rf")
predTest <- predict(modRF, newdata = vowel.test)
varImp(modRF)
install.packages("randomForest")
install.packages("randomForest")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train, importance = TRUE, proximity = TRUE)
library(randomForest)
modRF <- randomForest(y ~ ., data = vowel.train, importance = TRUE, proximity = TRUE)
predTest <- predict(modRF, newdata = vowel.test)
varImp(modRF)
library(caret)
varImp(modRF)
modRF$importance
modRF$MeanDecreaseGini
MeanDecreaseGini
varImp(modRF)[1]
sorrt(varImp(modRF)[1], decrease = TRUE)
sort(varImp(modRF)[1], decrease = TRUE)
sort(varImp(modRF)[1], decrease[1] = TRUE)
order(varImp(modRF)[1], decrease[1] = TRUE)
order(varImp(modRF)[1], decreasing = TRUE)
order(modRF$importance[12], decreasing = TRUE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
modFit1 <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
library(ggplot2)
modFit1 <- train(y ~ ., data = vowel.train, method = "rf")
modFit2 <- train(y ~ ., data = vowel.train, method = "gbm")
predRF <- predict(modFit1, vowel.test)
predGBM <- predict(modFit2, vowel.test)
confusionMatrix(predRF, vowel.test$y)
confusionMatrix(predGBM, vowel.test$y)
library(randomForest)
modRF <- randomForest(y ~ ., data = vowel.train, importance = TRUE, proximity = TRUE)
predRF2 <- predict(modRF, vowel.test)
confusionMatrix(predRF2, vowel.test$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train, importance = TRUE, proximity = TRUE)
predRF2 <- predict(modRF, vowel.test)
confusionMatrix(predRF2, vowel.test$y)
install.packages("e1071")
install.packages("e1071")
library(e1071)
?classAgreement
tab <- table(predRF2, predGBM)
classAgreement(tab)
classAgreement(tab, match.names = TRUE)
accuracy(predRF, vowel.test$y)
install.packages("AppliedPredictiveModeling")
install.paciages("caret")
install.packages("caret")
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("lubridate")
install.packages("e1071")
library(AppliedPredictiveModeling); library(caret); library(ElemStatLearn); library(pgmm); library(rpart); library(gbm); library(randomForest); library(e1071);
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit1 <- train(y ~ ., data = vowel.train, method = "rf")
modFit2 <- train(y ~ ., data = vowel.train, method = "gbm")
predRF1 <- predict(modFit1, vowel.test)
confusionMatrix(predRF, vowel.test$y)$overall[1]
confusionMatrix(predRF1, vowel.test$y)$overall[1]
predGBM <- predict(modFit2, vowel.test)
confusionMatrix(predGBM, vowel.test$y)$overall[1]
predAgrmt <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
predAgrmt <- data.frame(predRF1, predGBM, y = vowel.test$y)
Agrmt_df <- data.frame(predRF1, predGBM, y = vowel.test$y)
sum(predRF1[Agrmt_df$predRF1 == Agrmt_df$predGBM] == Agrmt_df$y[Agrmt_df$predRF1 == Agrmt_df$predGBM])/sum(Agrmt_df$predRF1 == Agrmt_df$predGBM)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
fitRF <- train(diagnosis ~ ., data = training, method = “rf”)
fitGBM <- train(diagnosis ~ ., data = training, method = “gbm”)
fitLDA <- train(diagnosis ~ ., data = training, method = “lda”)
fitRF <- train(diagnosis ~ ., data = training, method = "rf")
fitGBM <- train(diagnosis ~ ., data = training, method = "GBM")
fitGBM <- train(diagnosis ~ ., data = training, method = "gbm")
fitLDA <- train(diagnosis ~ ., data = training, method = "lda")
predRF <- predict(fitRF, newdata = testing)
predGBM <- predict(fitGBM, newdata = testing)
predLDA <- predict(fitLDA, newdata = testing)
confusionMatrix(predRF, testing$diagnosis)
confusionMatrix(predRF, testing$diagnosis)$overall[1]
confusionMatrix(predGBM, testing$diagnosis)$overall[1]
fitGBM <- train(diagnosis ~ ., data = testing, method = "gbm")
predGBM <- predict(fitGBM, newdata = testing)
confusionMatrix(predGBM, testing$diagnosis)
set.seed(62433)
fitGBM <- train(diagnosis ~ ., data = testing, method = "gbm")
predGBM <- predict(fitGBM, newdata = testing)
confusionMatrix(predGBM, testing$diagnosis)
confusionMatrix(predGBM, testing$diagnosis)$overall[1]
set.seed(62433)
fitLDA <- train(diagnosis ~ ., data = training, method = "lda")
predLDA <- predict(fitLDA, newdata = testing)
confusionMatrix(predLDA, testing$diagnosis)
confusionMatrix(predLDA, testing$diagnosis)$overall[1]
combDF <- data.frame(predRF, predGBM, predLDA, diagnosis = testing$diagnosis)
combFit <- train(diagnosis ~ ., method = "gam", data = combDF)
combPred <- predict(combFit, combDF)
combFit <- train(diagnosis ~ ., method = "rf", data = combDF)
predComb <- predict(combFit, combDF)
confusionMatrix(predComb, testing$diagnosis)
confusionMatrix(predComb, testing$diagnosis)$overall[1]
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(randomForest)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(adData)
set.seed(62433)
fitRF <- train(diagnosis ~ ., data = training, method = "rf")
fitGBM <- train(diagnosis ~ ., data = training, method = "gbm")
fitLDA <- train(diagnosis ~ ., data = training, method = "lda")
predRF <- predict(fitRF, newdata = testing)
predGBM <- predict(fitGBM, newdata = testing)
predLDA <- predict(fitLDA, newdata = testing)
confusionMatrix(predRF, testing$diagnosis)
confusionMatrix(predRF, testing$diagnosis)$overall[1]
confusionMatrix(predGBM, testing$diagnosis)$overall[1]
confusionMatrix(predLDA, testing$diagnosis)$overall[1]
combDF <- data.frame(predRF, predGBM, predLDA, diagnosis = testing$diagnosis)
fitComb <- train(diagnosis ~ ., data = combDF, method = "rf")
predComb <- predict(fitComb, combDF)
confusionMatrix(predComb, testing$diagnosis)$overall[1]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
library(ggplot2)
install.packages(“elasticnet”)
install.packages("elasticnet")
library(elasticnet)
?plot.enet
install.packages("glmnet")
library(glmnet)
fitLSO <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(fitLSO$$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(fitLSO$finalModel, xvar = "penalty", use.color = TRUE)
?bats
library(caret); library(lubridate);
install.packages("forecast")
library(forecast)
?bats
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
training = dat[year(dat$date) >2012,]
training = dat[year(dat$date) < 2012,]
library(lubridate)
training = dat[year(dat$date) < 2012,]
View(dat)
str(dat)
year(dat$date)
training = dat[year(dat$date) < "2012",]
training = dat[year(as.Date(dat$date, format = "%m/%d/%y") < "2012",]
training = dat[year(as.Date(dat$date, format = "%m/%d/%y") < 2012,]
training = dat[year(as.Date(dat$date, format = "%m/%d/%y")) < 2012,]
testing = dat[year(as.Date(dat$date, format = "%m/%d/%y")) > 2011,]
tstrain = ts(training$visitsTumblr)
fitTS <- bats(training)
?forecast
fitTS <- bats(tstrain)
length(unique(testing$date))
periods <- length(unique(testing$date))
fcastTS <- forecast(fitTS, level = 0.95, h = periods)
fcastTS
length(fcastTS)
length(fcastTS$point)
length(fcastTS$Point)
sum(fcastTS$lower < testing$visitsTumblr & testing$visitsTumblr < fcastTS$upper)/periods
library(caret)
library(caret); library(e1071);
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret); library(e1071);
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fitSVM <- svm(CompressiveStrength ~ ., data = training)
predSVM <- predict(fitSVM, newdata = testing)
accuracy(predSVM, testing$CompressiveStrength)
library(forecast)
accuracy(predSVM, testing$CompressiveStrength)
library(caret); library(randomForest); library(gbm); library(ElemStatLearn);
set.seed(3433)
library(caret); library(randomForest); library(gbm); library(ElemStatLearn);
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRF <- train(diagnosis ~ ., data = training, method = "rf")
predRF <- predict(fitRF, newdata = testing)
confusionMatrix(predRF, testing$diagnosis)$overall[1]
set.seed(62433)
fitGBM <- train(diagnosis ~ ., data = training, method = "gbm")
predGBM <- predict(fitGBM, newdata = testing)
confusionMatrix(predGBM, testing$diagnosis)$overall[1]
set.seed(62433)
fitLDA <- train(diagnosis ~ ., data = training, method = "lda")
predLDA <- predict(fitLDA, newdata = testing)
confusionMatrix(predLDA, testing$diagnosis)$overall[1]
combDF <- data.frame(fitRF, fitGBM, fitLDA, diagnosis = testing$diagnosis)
combDF <- data.frame(predRF, predGBM, predLDA, diagnosis = testing$diagnosis)
fitComb <- train(diagnosis ~ ., data = combDF, method = "rf")
predComb <- predict(fitComb, newdata = combDF)
confusionMatrix(predComb, testing$diagnosis)$overall[1]
set.seed(62433)
combDF <- data.frame(predRF, predGBM, predLDA, diagnosis = testing$diagnosis)
fitComb <- train(diagnosis ~ ., data = combDF, method = "rf")
predComb <- predict(fitComb, newdata = combDF)
confusionMatrix(predComb, testing$diagnosis)$overall[1]
setwd("User/harridw/Development/Coursera/Course8/WeightLifting")
setwd("/User/harridw/Development/Coursera/Course8/WeightLifting")
setwd("/Users/harridw/Development/Coursera/Course8/WeightLifting")
?read.csv
?fread
libary(dtplyr)
library(dtplyr)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dtplyr")
library(dplyr)
library(dtplyr)
?fread
install.packages("data.table")
library(data.table)
?fread
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
### Package Usage
packages <- c("plyr", "dplyr", "data.table", "dtplyr", "lubridate", "ggplot2", "scales",
"reshape2", "knitr", "R.cache", "stringr", "gtools", "quantreg",
"graphics", "corrplot", "broom", "rmarkdown", "caret", "randomForest",
"gbm", "forecast", "elasticnet", "e107", "glmnet", "quantmod", "rpart",
"rpart.plot", "rattle", "knitr")
ipak(packages)
library(e1071)
train.file = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test.file = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- fread(train.file, sep = ",", header = TRUE,
na.strings = c("NA", "N/A", "NULL", "Null", "null", " ", "  "))
testing <- fread(test.file, sep = ",", header = TRUE,
na.strings = c("NA", "N/A", "NULL", "Null", "null", " ", "  "))
class(training)
class(testing)
View(testing)
length(training$classe)
inTrain = createDataPartition(training$classe, p = 0.7, list = FALSE)
training = training[inTrain,]
validation = training[-inTrain,]
View(validation)
View(training)
highNA <- sapply(training, function(x) round(sum(is.na(x))/nrow(training, 3)))
highNA <- sapply(training, function(x) round(sum(is.na(x))/nrow(training), 3))
highNA
which(colnames(highNA) > .75)
str(highNA)
View(training)
whihc(highNA[1,] > 0.75)
which(highNA[1,] > 0.75)
colnames(highNA)
summary(highNA)
highNA <- data.frame(sapply(training, function(x) round(sum(is.na(x))/nrow(training), 3)))
View(highNA)
names(highNA)
highNA <- data.frame(sapply(training, function(x) pctNA=round(sum(is.na(x))/nrow(training), 3)))
View(highNA)
rm(highNA)
highNA <- data.frame(sapply(training, function(x) pctNA=round(sum(is.na(x))/nrow(training), 3)))
View(highNA)
rm(highNA)
class(training)
highNA <- data.frame(sapply(training, function(x) round(sum(is.na(x))/nrow(training), 3)))
colnames(highNA)[2] <- "pctNA"
colnames(highNA)
highNA <- data.frame(sapply(training, function(x) round(sum(is.na(x))/nrow(training), 3)))
colnames(highNA)[1] <- "pctNA"
View(highNA)
order(highNA$pctNA, decreasing = TRUE)
highNA[ ,order(highNA$pctNA, decreasing = TRUE))
highNA[ ,order(highNA$pctNA, decreasing = TRUE)]
highNA[ ,order(highNA$pctNA, decreasing = TRUE)]
highNA[ ,order(pctNA, decreasing = TRUE)]
highNA[ order(highNA$pctNA, decreasing = TRUE),]
highNA <- highNA[ order(highNA$pctNA, decreasing = TRUE),]
highNA <- data.frame(highNA[ order(highNA$pctNA, decreasing = TRUE),])
rm(highNA)
pctNA <- data.frame(sapply(training, function(x) round(sum(is.na(x))/nrow(training), 3)))
colnames(pctNA)[1] <- "pctNA"
highNA <- subset(pctNA, pctNA >0.75)
rownames(highNA)
train.trim <- training[ , -c(rownames(highNA))]
train.trim <- training[ , -rownames(highNA)]
excl <- c(rownames(highNA))
train.trim <- training[ , -c(excl)]
class(excl)
excl
list(excl)
c(excl)
train.trim <- training[,-names(training)%in%c(excl)]
names(training)
train.trim <- training[,-names(training) %in% c(excl)]
train.trim <- training[,names(training) %in% -c(excl)]
train.trim <- training[,names(training) %in% -excl]
train.trim <- training[,!(names(training) %in% c(excl))]
train.trim
train.trim <- training[,-which(names(training) %in% c(excl))]
train.trim
train.trim <- training[1:nrow(training),-which(names(training) %in% c(excl))]
train.trim <- data.frame(training[,-which(names(training) %in% c(excl))])
View(train.trim)
rm(train.trim)
which(names(training) %in% c(excl))
train.trim <- subset(training, select = -c(excl))
class(excl)
excl <- c(excl)
class(excl)
train.trim <- training[,c(excl)]
train.trim
head(train.trim)
excl.var <- training[,-which(names(training) %in% c(excl))]
excl.var <- training[,!which(names(training) %in% c(excl))]
excl.var <- c(which(names(training) %in% c(excl)))
class(excl.var)
train.trim <- training[,-c(excl.var)]
train.trim
select(training, -c(excl))
select(training, -excl)
rm(excl)
rm(excl.var)
rm(train.trim)
excl <- c(rownames(highNA))
which[names(training) %in% excl]
trainsub <- training[,-which(names(training) %in% excl)]
trainsub <- training[,-which(names(training) %in% c(excl)]
trainsub <- training[,-which(names(training) %in% c(excl))]
trainsub <- select(training, -c(excl))
trainsub <- select(training, -excl)
trainsub <- select(training, -c(rownames(highNA)))
library(plyr)
library(dplyr)
library(data.table)
library(dtplyr)
train.trim <- training[,c(excl):=NULL]
rm(trainsub)
rm(train.trim)
head(highNA, n = 20)
class(training$classe)
unique(training$classe)
nzv <- nearZeroVar(training, freqCut = 80, uniqueCut = 0.1)
nzv <- nearZeroVar(training, freqCut = 80/20, uniqueCut = 0.1)
nzv
nzv <- nearZeroVar(training, freqCut = 80/20, uniqueCut = 0.1, saveMetrics = TRUE)
View(nzv)
